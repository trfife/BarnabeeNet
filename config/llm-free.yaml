# BarnabeeNet LLM Configuration - FREE/LOW-COST TIER
# Uses the cheapest available models on OpenRouter
#
# These models provide good quality at minimal cost:
# - google/gemini-2.0-flash-001 - $0.10/$0.40 per 1M tokens (very cheap)
# - deepseek/deepseek-chat - $0.14/$0.28 per 1M tokens (cheapest quality model)
# - meta-llama/llama-3.3-70b-instruct - $0.30/$0.30 per 1M tokens
#
# Note: True free models (:free suffix) may have availability issues.
# This config uses ultra-low-cost models for reliable operation.

# OpenRouter API settings
openrouter:
  site_url: "https://barnabeenet.local"
  site_name: "BarnabeeNet"

# Agent model configurations - LOW-COST TIER
agents:
  # Meta Agent: Routes requests to appropriate agent
  # LOW-COST: Gemini Flash is fastest and cheapest ($0.10/$0.40 per 1M)
  meta:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.2
    max_tokens: 200
    description: "Fast routing decisions for every request (LOW-COST)"

  # Instant Agent: Quick pattern-matched responses
  # LOW-COST: Gemini Flash for fast responses
  instant:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.3
    max_tokens: 300
    description: "Fast responses for simple queries (LOW-COST)"

  # Action Agent: Device control decisions
  # LOW-COST: DeepSeek Chat - very cheap and reliable
  action:
    model: "deepseek/deepseek-chat"
    temperature: 0.2
    max_tokens: 500
    description: "Device control and home automation (LOW-COST)"

  # Interaction Agent: Complex conversations
  # LOW-COST: DeepSeek Chat - good quality at lowest cost
  interaction:
    model: "deepseek/deepseek-chat"
    temperature: 0.7
    max_tokens: 1500
    description: "Complex conversations, advice, personality (LOW-COST)"

  # Memory Agent: Summarization for memory storage
  # LOW-COST: DeepSeek Chat for efficient summarization
  memory:
    model: "deepseek/deepseek-chat"
    temperature: 0.3
    max_tokens: 800
    description: "Memory generation and summarization (LOW-COST)"

# =============================================================================
# Activity-Level Configuration - LOW-COST TIER
# =============================================================================

activities:
  # ---------------------------------------------------------------------------
  # MetaAgent Activities - LOW-COST
  # ---------------------------------------------------------------------------
  meta.classify_intent:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.2
    max_tokens: 150
    priority: speed
    description: "Intent classification (LOW-COST)"

  meta.evaluate_context:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.3
    max_tokens: 100
    priority: speed
    description: "Context and mood evaluation (LOW-COST)"

  meta.generate_queries:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.4
    max_tokens: 200
    priority: speed
    description: "Generate memory search queries (LOW-COST)"

  # ---------------------------------------------------------------------------
  # ActionAgent Activities - LOW-COST
  # ---------------------------------------------------------------------------
  action.parse_intent:
    model: "deepseek/deepseek-chat"
    temperature: 0.2
    max_tokens: 300
    priority: accuracy
    description: "Parse device control intent (LOW-COST)"

  action.resolve_entities:
    model: "deepseek/deepseek-chat"
    temperature: 0.1
    max_tokens: 200
    priority: accuracy
    description: "Resolve entity names to HA IDs (LOW-COST)"

  action.generate_confirm:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.5
    max_tokens: 100
    priority: speed
    description: "Generate action confirmations (LOW-COST)"

  action.generate_error:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.5
    max_tokens: 150
    priority: speed
    description: "Generate helpful error messages (LOW-COST)"

  # ---------------------------------------------------------------------------
  # InteractionAgent Activities - LOW-COST
  # ---------------------------------------------------------------------------
  interaction.respond:
    model: "deepseek/deepseek-chat"
    temperature: 0.7
    max_tokens: 1500
    priority: quality
    description: "Main conversational responses (LOW-COST)"

  interaction.followup:
    model: "deepseek/deepseek-chat"
    temperature: 0.7
    max_tokens: 1000
    priority: quality
    description: "Follow-up in conversation (LOW-COST)"

  interaction.empathy:
    model: "deepseek/deepseek-chat"
    temperature: 0.8
    max_tokens: 800
    priority: quality
    description: "Empathetic/emotional responses (LOW-COST)"

  interaction.factual:
    model: "deepseek/deepseek-chat"
    temperature: 0.3
    max_tokens: 1000
    priority: accuracy
    description: "Factual question answering (LOW-COST)"

  # ---------------------------------------------------------------------------
  # MemoryAgent Activities - LOW-COST
  # ---------------------------------------------------------------------------
  memory.generate:
    model: "deepseek/deepseek-chat"
    temperature: 0.3
    max_tokens: 500
    priority: quality
    description: "Generate memories from events (LOW-COST)"

  memory.extract_facts:
    model: "deepseek/deepseek-chat"
    temperature: 0.2
    max_tokens: 400
    priority: accuracy
    description: "Extract facts from conversation (LOW-COST)"

  memory.summarize:
    model: "deepseek/deepseek-chat"
    temperature: 0.3
    max_tokens: 300
    priority: quality
    description: "Summarize for memory storage (LOW-COST)"

  memory.rank:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.2
    max_tokens: 100
    priority: speed
    description: "Rank memory relevance (LOW-COST)"

  # ---------------------------------------------------------------------------
  # InstantAgent Activities - LOW-COST
  # ---------------------------------------------------------------------------
  instant.fallback:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.5
    max_tokens: 200
    priority: speed
    description: "Fallback for instant patterns (LOW-COST)"

  # ---------------------------------------------------------------------------
  # ProfileAgent Activities - LOW-COST
  # ---------------------------------------------------------------------------
  profile.generate:
    model: "deepseek/deepseek-chat"
    temperature: 0.3
    max_tokens: 2000
    priority: quality
    description: "Generate/update family member profiles (LOW-COST)"

  profile.summarize_diff:
    model: "google/gemini-2.0-flash-001"
    temperature: 0.3
    max_tokens: 300
    priority: speed
    description: "Summarize profile changes (LOW-COST)"

# =============================================================================
# Model Pricing Reference - LOW-COST TIER
# =============================================================================
pricing:
  "google/gemini-2.0-flash-001":
    input: 0.10
    output: 0.40
  "deepseek/deepseek-chat":
    input: 0.14
    output: 0.28
  "meta-llama/llama-3.3-70b-instruct":
    input: 0.30
    output: 0.30

# Signal logging settings
signals:
  retention_days: 30
  stream_max_length: 10000
  log_full_prompts: true
  log_injected_context: true
