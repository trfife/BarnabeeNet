# BarnabeeNet LLM Configuration - FREE TIER
# Uses OpenRouter free models (append :free to model IDs)
#
# Free models have:
# - No cost per token
# - Lower rate limits
# - May have availability constraints during peak times
#
# Best free models as of 2026:
# - google/gemini-2.0-flash-exp:free - Fast, 1M context, multimodal
# - meta-llama/llama-3.3-70b-instruct:free - GPT-4 level quality
# - deepseek/deepseek-chat:free - Good quality, fast

# OpenRouter API settings
openrouter:
  site_url: "https://barnabeenet.local"
  site_name: "BarnabeeNet"

# Agent model configurations - FREE TIER
agents:
  # Meta Agent: Routes requests to appropriate agent
  # FREE: Gemini Flash is free and fastest
  meta:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.2
    max_tokens: 200
    description: "Fast routing decisions for every request (FREE)"

  # Instant Agent: Quick pattern-matched responses
  # FREE: Gemini Flash for sub-100ms responses
  instant:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.3
    max_tokens: 300
    description: "Fast responses for simple queries (FREE)"

  # Action Agent: Device control decisions
  # FREE: Llama 3.3 70B for reliable device control
  action:
    model: "meta-llama/llama-3.3-70b-instruct:free"
    temperature: 0.2
    max_tokens: 500
    description: "Device control and home automation (FREE)"

  # Interaction Agent: Complex conversations
  # FREE: Llama 3.3 70B - closest to GPT-4 quality
  interaction:
    model: "meta-llama/llama-3.3-70b-instruct:free"
    temperature: 0.7
    max_tokens: 1500
    description: "Complex conversations, advice, personality (FREE)"

  # Memory Agent: Summarization for memory storage
  # FREE: Gemini Flash for efficient summarization
  memory:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.3
    max_tokens: 800
    description: "Memory generation and summarization (FREE)"

# =============================================================================
# Activity-Level Configuration - FREE TIER
# =============================================================================

activities:
  # ---------------------------------------------------------------------------
  # MetaAgent Activities - FREE
  # ---------------------------------------------------------------------------
  meta.classify_intent:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.2
    max_tokens: 150
    priority: speed
    description: "Intent classification (FREE)"

  meta.evaluate_context:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.3
    max_tokens: 100
    priority: speed
    description: "Context and mood evaluation (FREE)"

  meta.generate_queries:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.4
    max_tokens: 200
    priority: speed
    description: "Generate memory search queries (FREE)"

  # ---------------------------------------------------------------------------
  # ActionAgent Activities - FREE
  # ---------------------------------------------------------------------------
  action.parse_intent:
    model: "meta-llama/llama-3.3-70b-instruct:free"
    temperature: 0.2
    max_tokens: 300
    priority: accuracy
    description: "Parse device control intent (FREE)"

  action.resolve_entities:
    model: "meta-llama/llama-3.3-70b-instruct:free"
    temperature: 0.1
    max_tokens: 200
    priority: accuracy
    description: "Resolve entity names to HA IDs (FREE)"

  action.generate_confirm:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.5
    max_tokens: 100
    priority: speed
    description: "Generate action confirmations (FREE)"

  action.generate_error:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.5
    max_tokens: 150
    priority: speed
    description: "Generate helpful error messages (FREE)"

  # ---------------------------------------------------------------------------
  # InteractionAgent Activities - FREE
  # ---------------------------------------------------------------------------
  interaction.respond:
    model: "meta-llama/llama-3.3-70b-instruct:free"
    temperature: 0.7
    max_tokens: 1500
    priority: quality
    description: "Main conversational responses (FREE)"

  interaction.followup:
    model: "meta-llama/llama-3.3-70b-instruct:free"
    temperature: 0.7
    max_tokens: 1000
    priority: quality
    description: "Follow-up in conversation (FREE)"

  interaction.empathy:
    model: "meta-llama/llama-3.3-70b-instruct:free"
    temperature: 0.8
    max_tokens: 800
    priority: quality
    description: "Empathetic/emotional responses (FREE)"

  interaction.factual:
    model: "meta-llama/llama-3.3-70b-instruct:free"
    temperature: 0.3
    max_tokens: 1000
    priority: accuracy
    description: "Factual question answering (FREE)"

  # ---------------------------------------------------------------------------
  # MemoryAgent Activities - FREE
  # ---------------------------------------------------------------------------
  memory.generate:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.3
    max_tokens: 500
    priority: quality
    description: "Generate memories from events (FREE)"

  memory.extract_facts:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.2
    max_tokens: 400
    priority: accuracy
    description: "Extract facts from conversation (FREE)"

  memory.summarize:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.3
    max_tokens: 300
    priority: quality
    description: "Summarize for memory storage (FREE)"

  memory.rank:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.2
    max_tokens: 100
    priority: speed
    description: "Rank memory relevance (FREE)"

  # ---------------------------------------------------------------------------
  # InstantAgent Activities - FREE
  # ---------------------------------------------------------------------------
  instant.fallback:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.5
    max_tokens: 200
    priority: speed
    description: "Fallback for instant patterns (FREE)"

  # ---------------------------------------------------------------------------
  # ProfileAgent Activities - FREE
  # ---------------------------------------------------------------------------
  profile.generate:
    model: "meta-llama/llama-3.3-70b-instruct:free"
    temperature: 0.3
    max_tokens: 2000
    priority: quality
    description: "Generate/update family member profiles (FREE)"

  profile.summarize_diff:
    model: "google/gemini-2.0-flash-exp:free"
    temperature: 0.3
    max_tokens: 300
    priority: speed
    description: "Summarize profile changes (FREE)"

# =============================================================================
# Model Pricing Reference - FREE TIER
# =============================================================================
pricing:
  "google/gemini-2.0-flash-exp:free":
    input: 0.0
    output: 0.0
  "meta-llama/llama-3.3-70b-instruct:free":
    input: 0.0
    output: 0.0
  "deepseek/deepseek-chat:free":
    input: 0.0
    output: 0.0
  "mistralai/mistral-7b-instruct:free":
    input: 0.0
    output: 0.0

# Signal logging settings
signals:
  retention_days: 30
  stream_max_length: 10000
  log_full_prompts: true
  log_injected_context: true
